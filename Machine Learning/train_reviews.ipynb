{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs8qnEutiAe5",
        "outputId": "3696f222-1435-44a1-cb6c-4b517b969982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_ywnxjAriCet"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "import os\n",
        "os.chdir(root_dir + 'Recommend_Music')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU3ryVJ2q8VQ",
        "outputId": "0c81feab-7e84-414c-eccd-6e5eb2806911"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n"
          ]
        }
      ],
      "source": [
        "#importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')#tokenize the text in the dataset.\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import string\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "loaded_model = pickle.load(open('Project_Saved_Models/model_review.pkl', 'rb'))\n",
        "vectorizer = pickle.load(open('Project_Saved_Models/vectorizer_review.pkl', 'rb'))\n",
        "\n",
        "\n",
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_numbers(text):\n",
        "    number_pattern = r'\\d+'\n",
        "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "    return without_number\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    removed = []\n",
        "    stop_words = list(stopwords.words(\"english\"))\n",
        "    stop_words.remove('not')\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        if tokens[i] not in stop_words:\n",
        "            removed.append(tokens[i])\n",
        "    return \" \".join(removed)\n",
        "\n",
        "def remove_extra_white_spaces(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_sc\n",
        "\n",
        "def lemmatizing(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
        "        tokens[i] = lemma_word\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "text=\"this song is very nice\"\n",
        "a=convert_to_lower(text)\n",
        "b=remove_numbers(a)\n",
        "c=remove_punctuation(b)\n",
        "d=remove_stopwords(c)\n",
        "e=remove_extra_white_spaces(d)\n",
        "f=lemmatizing(e)\n",
        "\n",
        "\n",
        "X_test = vectorizer.transform([f])\n",
        "\n",
        "X_test = X_test.toarray()\n",
        "\n",
        "result=loaded_model.predict(X_test)\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpo_F8KPgJuE",
        "outputId": "7cc5e9e7-4720-4439-bd8e-6adb65526fa0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA LOADED\n",
            "\n",
            "                                              Review  Rating\n",
            "0  i think i actually under-rate ok computer if a...     5.0\n",
            "1  i get why radiohead rub a lot of people the wr...     5.0\n",
            "2  i would like to think i am good about not lett...     4.5\n",
            "3  there are radiohead devotees like there were o...     4.0\n",
            "4  i wrote a shining excellent review for this al...     5.0\n",
            "Index(['Review', 'Rating'], dtype='object')\n",
            "************************************************** \n",
            "\n",
            "Review      6\n",
            "Rating    262\n",
            "dtype: int64\n",
            "                                                 Review  Rating\n",
            "0     i think i actually under-rate ok computer if a...     5.0\n",
            "1     i get why radiohead rub a lot of people the wr...     5.0\n",
            "2     i would like to think i am good about not lett...     4.5\n",
            "3     there are radiohead devotees like there were o...     4.0\n",
            "4     i wrote a shining excellent review for this al...     5.0\n",
            "...                                                 ...     ...\n",
            "9995  did not like it as much as their earlier stuff...     4.0\n",
            "9996  well... it is not a bad album but it is far to...     5.0\n",
            "9997  although this was below my expectations maybe ...     3.5\n",
            "9998  in rainbows is the first radiohead album i eve...     4.5\n",
            "9999  disc 2 of in rainbows is 6 brilliant little so...     4.5\n",
            "\n",
            "[9732 rows x 2 columns]\n",
            "Review    0\n",
            "Rating    0\n",
            "dtype: int64\n",
            "5.0    4897\n",
            "4.5    1835\n",
            "4.0    1231\n",
            "3.5     665\n",
            "3.0     434\n",
            "2.5     260\n",
            "2.0     166\n",
            "1.0      85\n",
            "0.5      81\n",
            "1.5      78\n",
            "Name: Rating, dtype: int64\n",
            "                                                 Review  Rating\n",
            "0     i think i actually under-rate ok computer if a...     5.0\n",
            "1     i get why radiohead rub a lot of people the wr...     5.0\n",
            "4     i wrote a shining excellent review for this al...     5.0\n",
            "6     radiohead i nigel godrich wytworzyli prawdziwi...     5.0\n",
            "8     i can sort of understand the praise this album...     2.0\n",
            "...                                                 ...     ...\n",
            "9984  i like this more than ok computer. deal with i...     5.0\n",
            "9986  my fascination with radiohead began with this ...     5.0\n",
            "9987  18 great songs of in rainbows  have their fans...     5.0\n",
            "9992  this album is totally amazing and unique ten t...     5.0\n",
            "9996  well... it is not a bad album but it is far to...     5.0\n",
            "\n",
            "[5307 rows x 2 columns]\n",
            "5.0    4897\n",
            "2.0     166\n",
            "1.0      85\n",
            "0.5      81\n",
            "1.5      78\n",
            "Name: Rating, dtype: int64\n",
            "                                                 Review    Rating\n",
            "0     i think i actually under-rate ok computer if a...  Positive\n",
            "1     i get why radiohead rub a lot of people the wr...  Positive\n",
            "4     i wrote a shining excellent review for this al...  Positive\n",
            "6     radiohead i nigel godrich wytworzyli prawdziwi...  Positive\n",
            "8     i can sort of understand the praise this album...  Negative\n",
            "...                                                 ...       ...\n",
            "9984  i like this more than ok computer. deal with i...  Positive\n",
            "9986  my fascination with radiohead began with this ...  Positive\n",
            "9987  18 great songs of in rainbows  have their fans...  Positive\n",
            "9992  this album is totally amazing and unique ten t...  Positive\n",
            "9996  well... it is not a bad album but it is far to...  Positive\n",
            "\n",
            "[5307 rows x 2 columns]\n",
            "                                                 Review  Rating\n",
            "0     i think i actually under-rate ok computer if a...       1\n",
            "1     i get why radiohead rub a lot of people the wr...       1\n",
            "4     i wrote a shining excellent review for this al...       1\n",
            "6     radiohead i nigel godrich wytworzyli prawdziwi...       1\n",
            "8     i can sort of understand the praise this album...       0\n",
            "...                                                 ...     ...\n",
            "9984  i like this more than ok computer. deal with i...       1\n",
            "9986  my fascination with radiohead began with this ...       1\n",
            "9987  18 great songs of in rainbows  have their fans...       1\n",
            "9992  this album is totally amazing and unique ten t...       1\n",
            "9996  well... it is not a bad album but it is far to...       1\n",
            "\n",
            "[5307 rows x 2 columns]\n",
            "1    4897\n",
            "0     410\n",
            "Name: Rating, dtype: int64\n",
            "************************************************** \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:72: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:73: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:119: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:127: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9422473320778405\n"
          ]
        }
      ],
      "source": [
        "#importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')#tokenize the text in the dataset.\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import string\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def print_star():\n",
        "    print('*'*50, '\\n')\n",
        "\n",
        "#reading dataset\n",
        "df = pd.read_csv(\"Project_Dataset/music_album_reviews_dataset.csv\")\n",
        "print(\"DATA LOADED\\n\")\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "df=df[:10000]\n",
        "print_star()\n",
        "\n",
        "#######################Preprocessing\n",
        "#checking null values\n",
        "print( df.isnull().sum())\n",
        "\n",
        "#removing rows that contain null values\n",
        "new_df = df.dropna()\n",
        "print(new_df)\n",
        "\n",
        "#checking null values\n",
        "print( new_df.isnull().sum())\n",
        "\n",
        "#print(new_df['Rating'].value_counts(ascending=False))\n",
        "\n",
        "#dropping unnecessary rows\n",
        "new_df.drop(new_df[new_df['Rating'] == 4.5].index, inplace = True)\n",
        "new_df.drop(new_df[new_df['Rating'] == 4.0].index, inplace = True)\n",
        "new_df.drop(new_df[new_df['Rating'] == 3.5].index, inplace = True)\n",
        "new_df.drop(new_df[new_df['Rating'] == 3.0].index, inplace = True)\n",
        "new_df.drop(new_df[new_df['Rating'] == 2.5].index, inplace = True)\n",
        "print(new_df)\n",
        "#print(new_df['Rating'].value_counts(ascending=False))\n",
        "\n",
        "#replace labels with corresponding categorical values\n",
        "new_df['Rating']=new_df['Rating'].replace(5.0,\"Positive\")\n",
        "new_df['Rating']=new_df['Rating'].replace(2.0,\"Negative\")\n",
        "new_df['Rating']=new_df['Rating'].replace(1.5,\"Negative\")\n",
        "new_df['Rating']=new_df['Rating'].replace(1.0,\"Negative\")\n",
        "new_df['Rating']=new_df['Rating'].replace(0.5,\"Negative\")\n",
        "\n",
        "print(new_df)\n",
        "#convert categorical values to numerical values\n",
        "new_df['Rating']=new_df['Rating'].replace(\"Positive\",1)\n",
        "new_df['Rating']=new_df['Rating'].replace(\"Negative\",0)\n",
        "\n",
        "print(new_df)\n",
        "#print(new_df['Rating'].value_counts(ascending=False))\n",
        "#new_df.to_csv('Project_Dataset/final_music_album_reviews_dataset.csv',index=False)\n",
        "print_star()\n",
        "\n",
        "#convert to lowercase\n",
        "def convert_to_lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "new_df['Review'] = new_df['Review'].apply(lambda x: convert_to_lower(x))\n",
        "\n",
        "#remove digits\n",
        "def remove_numbers(text):\n",
        "    number_pattern = r'\\d+'\n",
        "    without_number = re.sub(pattern=number_pattern, repl=\" \", string=text)\n",
        "    return without_number\n",
        "\n",
        "new_df['Review'] = new_df['Review'].apply(lambda x: remove_numbers(x))\n",
        "\n",
        "#remove punctuations\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "new_df['Review'] = new_df['Review'].apply(lambda x: remove_punctuation(x))\n",
        "\n",
        "#remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    removed = []\n",
        "    stop_words = list(stopwords.words(\"english\"))\n",
        "    stop_words.remove('not')\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        if tokens[i] not in stop_words:\n",
        "            removed.append(tokens[i])\n",
        "    return \" \".join(removed)\n",
        "\n",
        "new_df['Review'] = new_df['Review'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "#remove_extra_white_spaces\n",
        "def remove_extra_white_spaces(text):\n",
        "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
        "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string=text)\n",
        "    return without_sc\n",
        "\n",
        "new_df['Review'] = new_df['Review'].apply(lambda x: remove_extra_white_spaces(x))\n",
        "\n",
        "#apply lemmatization\n",
        "def lemmatizing(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text)\n",
        "    for i in range(len(tokens)):\n",
        "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
        "        tokens[i] = lemma_word\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "new_df['Review'] = new_df['Review'].apply(lambda x: lemmatizing(x))\n",
        "\n",
        "\n",
        "# Seperating data and labels\n",
        "data=new_df[\"Review\"]\n",
        "labels=new_df[\"Rating\"]\n",
        "\n",
        "\n",
        "#Perform train-test splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.30)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "Counter(y_train)\n",
        "\n",
        "#Feature Extraction using tf-idf vectorizer\n",
        "#initialise tf-idf vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "#perform feature extraction\n",
        "vectorizer.fit(X_train)\n",
        "\n",
        "#train set\n",
        "X_train_tf = vectorizer.transform(X_train)\n",
        "X_train_tf = X_train_tf.toarray()\n",
        "#test set\n",
        "X_test_tf = vectorizer.transform(X_test)\n",
        "X_test_tf = X_test_tf.toarray()\n",
        "\n",
        "#Data balancing\n",
        "#initialize RandomoverSampler\n",
        "ROS = RandomOverSampler(sampling_strategy=1)\n",
        "X_train_ros, y_train_ros = ROS.fit_resample(X_train_tf, y_train)\n",
        "\n",
        "Counter(y_train_ros)\n",
        "\n",
        "#save vectorizer\n",
        "pickle.dump(vectorizer,open('Project_Saved_Models/vectorizer_review.pkl', 'wb'))\n",
        "\n",
        "# import support vector classifier \n",
        "# \"Support Vector Classifier\"\n",
        "from sklearn.svm import SVC  \n",
        "clf = SVC(kernel='linear') \n",
        "  \n",
        "# training \n",
        "clf.fit(X_train_ros, y_train_ros)\n",
        "#prediction on test set\n",
        "y_preds = clf.predict(X_test_tf)\n",
        "\n",
        "#calculate accuracy\n",
        "print(accuracy_score(y_test, y_preds))\n",
        "\n",
        "#Save the trained model\n",
        "pickle.dump(clf, open('Project_Saved_Models/model_review.pkl', 'wb'))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
